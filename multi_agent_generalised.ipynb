{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traci\n",
    "import sys\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import internal modules\n",
    "from rl_package.rl_logic.Environnement import EnvironnementSumo\n",
    "from rl_package.rl_logic.Agent import AgentSumo\n",
    "from rl_package.params import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "#SUMO_BIN = r\"C:/Program Files/rl_project/Eclipse/Sumo/bin/sumo.exe\"\n",
    "SIMUL_CONFIG = r\"double_traffic/double_traffic.sumo.cfg\"\n",
    "\n",
    "\n",
    "WINDOW=2000\n",
    "BATCH_SIZE=6\n",
    "# SUMO command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess():\n",
    "    \"\"\"\n",
    "    Determines the number of inputs and outputs required for the model.\n",
    "    \"\"\"\n",
    "    sumoCmd = [SUMO_BIN, \"-c\", SIMUL_CONFIG, '--start', '--no-warnings']\n",
    "    env = EnvironnementSumo(sumoCmd, WINDOW)\n",
    "    inputs_per_agents = []\n",
    "    outputs_per_agents = []\n",
    "    for trafficlight in env.trafficlights_ids:\n",
    "\n",
    "    # Get the number of lanes that are not intersections\n",
    "        n_lanes = len(env.control_lanes(trafficlight))\n",
    "        inputs_per_agents.append(n_lanes*2)\n",
    "\n",
    "        # Get the number of valid traffic light phases (excluding yellow phases)\n",
    "        n_outputs = len(env.get_phase_without_yellow(trafficlight)[0])\n",
    "        outputs_per_agents.append(n_outputs)\n",
    "\n",
    "    # Get the number of agents\n",
    "\n",
    "    env.close()\n",
    "    return inputs_per_agents, outputs_per_agents  # Inputs: lane states (queue + vehicle count), Outputs: traffic light phases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 1ms, vehicles TOT 0 ACT 0 BUF 0)                      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([64, 64], [4, 4])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_models(inputs_per_agents, outputs_per_agents, type_model=\"DQN\"):\n",
    "    \"\"\"\n",
    "    Trains a reinforcement learning model to optimize traffic lights.\n",
    "    Saves the trained model after completion.\n",
    "    \"\"\"\n",
    "\n",
    "    agents = [AgentSumo(type_model, inputs, outputs) for inputs,outputs  in zip(inputs_per_agents,outputs_per_agents)]\n",
    "    for agent in agents:\n",
    "        agent.build_model()\n",
    "        # model_path = f\"models/{type_model}.keras\"\n",
    "        # if os.path.exists(model_path):\n",
    "        #     print(f\"ðŸ”„ Loading pre-trained model {type_model}...\")\n",
    "        #     agents[i].model_action=tf.keras.models.load_model(model_path)\n",
    "        #     agents[i].model_target=tf.keras.models.load_model(model_path)\n",
    "        #print('fvvgfv', agent.n_inputs, agent.n_outputs)\n",
    "    sumoCmd = [SUMO_BIN, \"-c\", SIMUL_CONFIG, '--start', '--no-warnings']\n",
    "\n",
    "    for episode in range(EPISODE):\n",
    "        print(f'ðŸ”„ Episode {episode}/{EPISODE}')\n",
    "        env = EnvironnementSumo(sumoCmd, WINDOW)\n",
    "        #epsilon = max(1 - episode / EPISODE, 0.01)  # Decaying epsilon for exploration\n",
    "        epsilon=0.2\n",
    "        # rÃ©cupÃ¨re le nom des agents\n",
    "        traffic_lights = env.trafficlights_ids\n",
    "\n",
    "\n",
    "\n",
    "        # appel une fonction et rÃ©cupÃ¨re une partie du dictionnaire\n",
    "        states = [env.get_states_per_traffic_light(traffic_light) for traffic_light in traffic_lights]\n",
    "\n",
    "        for _ in range(50):  # Steps per episode\n",
    "            actions = [agent.epsilon_greedy_policy(np.array(states[i]),epsilon) for i, agent in enumerate(agents)]\n",
    "            #print('ici')\n",
    "            next_states, rewards = env.step(actions)\n",
    "            for i in range(len(agents)):\n",
    "                agents[i].add_to_memory(np.array(states[i]), np.array(actions[i]), np.array(rewards[i]), np.array(next_states[i]))\n",
    "            states = next_states\n",
    "            # Train the model if there is enough experience in memory\n",
    "\n",
    "            if len(agents[0].replay_buffer) >= BATCH_SIZE * 1:\n",
    "                #print('train')\n",
    "                for agent in agents:\n",
    "                    #print('la')\n",
    "                    agent.training_step(BATCH_SIZE)\n",
    "\n",
    "            # Stop the simulation if there are no vehicles left\n",
    "            if env.get_total_number_vehicles() == 0:\n",
    "                break\n",
    "\n",
    "        # Update target network every 5 episodes for Double/Dueling DQN\n",
    "        if episode % 5 == 0 and type_model != 'DQN':\n",
    "            for agent in agents:\n",
    "                agent.model_target.set_weights(agent.model_action.get_weights())\n",
    "\n",
    "        env.close()\n",
    "\n",
    "    # Save the trained model\n",
    "    # model_path = f\"models/{type_model}.keras\"\n",
    "    # agents[i].model_action.save(model_path)\n",
    "    # print(f\"âœ… Model saved at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scenario(agent):\n",
    "    \"\"\"\n",
    "    Runs a SUMO simulation using the trained agent.\n",
    "    \"\"\"\n",
    "    sumoCmd = [SUMO_GUI_BIN, \"-c\", SIMUL_CONFIG, '--start', '--no-warnings']\n",
    "    env = EnvironnementSumo(sumoCmd, WINDOW)\n",
    "    env.full_simul(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 1ms, vehicles TOT 0 ACT 0 BUF 0)                      \n",
      "ðŸš€ CrÃ©ation d'un nouveau modÃ¨le 2DQN...\n",
      "ðŸš€ CrÃ©ation d'un nouveau modÃ¨le 2DQN...\n",
      "ðŸ”„ Episode 0/50\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1000.00 (1ms ~= 10.00*RT, ~141000.00UPS, TraCI: 199ms, vehicles TOT 988 ACT 141 BUF 2 ~= 10.00*RT, ~134000.00UPS, TraCI: 286ms, vehicles TOT 752 ACT 134 BUF 1\n",
      "ðŸ”„ Episode 1/50\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1000.00 (1ms ~= 10.00*RT, ~243000.00UPS, TraCI: 215ms, vehicles TOT 861 ACT 243 BUF 3 ~= 10.00*RT, ~166000.00UPS, TraCI: 236ms, vehicles TOT 732 ACT 166 BUF 1\n",
      "ðŸ”„ Episode 2/50\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1000.00 (0ms ?*RT. ?UPS, TraCI: 257ms, vehicles TOT 982 ACT 169 BUF 209)              ?*RT. ?UPS, TraCI: 228ms, vehicles TOT 784 ACT 160 BUF 80)              \n",
      "ðŸ”„ Episode 3/50\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1000.00 (0ms ?*RT. ?UPS, TraCI: 189ms, vehicles TOT 1002 ACT 103 BUF 189)             ~= 10.00*RT, ~107000.00UPS, TraCI: 271ms, vehicles TOT 752 ACT 107 BUF 1\n",
      "ðŸ”„ Episode 4/50\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1000.00 (0ms ?*RT. ?UPS, TraCI: 193ms, vehicles TOT 981 ACT 178 BUF 210)              ?*RT. ?UPS, TraCI: 245ms, vehicles TOT 768 ACT 97 BUF 96)               \n",
      "ðŸ”„ Episode 5/50\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupt signal received, trying to exit gracefully.440ms, vehicles TOT 421 ACT 100 BUF 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m type_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2DQN\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m inputs_per_agents, outputs_per_agents \u001b[38;5;241m=\u001b[39m preprocess()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_per_agents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_per_agents\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtype_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[97], line 34\u001b[0m, in \u001b[0;36mtrain_models\u001b[0;34m(inputs_per_agents, outputs_per_agents, type_model)\u001b[0m\n\u001b[1;32m     32\u001b[0m actions \u001b[38;5;241m=\u001b[39m [agent\u001b[38;5;241m.\u001b[39mepsilon_greedy_policy(np\u001b[38;5;241m.\u001b[39marray(states[i]),epsilon) \u001b[38;5;28;01mfor\u001b[39;00m i, agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(agents)]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#print('ici')\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m next_states, rewards \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(agents)):\n\u001b[1;32m     36\u001b[0m     agents[i]\u001b[38;5;241m.\u001b[39madd_to_memory(np\u001b[38;5;241m.\u001b[39marray(states[i]), np\u001b[38;5;241m.\u001b[39marray(actions[i]), np\u001b[38;5;241m.\u001b[39marray(rewards[i]), np\u001b[38;5;241m.\u001b[39marray(next_states[i]))\n",
      "File \u001b[0;32m~/code/psels/RL_traffic/rl_package/rl_logic/Environnement.py:54\u001b[0m, in \u001b[0;36mEnvironnementSumo.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     51\u001b[0m     traci\u001b[38;5;241m.\u001b[39mtrafficlight\u001b[38;5;241m.\u001b[39msetPhase(traffic_light,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mactions[i])\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow):\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mtraci\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulationStep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m next_states \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_states_per_traffic_light(traffic_light) \u001b[38;5;28;01mfor\u001b[39;00m traffic_light \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrafficlights_ids]\n\u001b[1;32m     58\u001b[0m rewards \u001b[38;5;241m=\u001b[39m [calculate_reward(states[i],next_states[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(actions))]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/RL_traffic/lib/python3.10/site-packages/traci/main.py:198\u001b[0m, in \u001b[0;36msimulationStep\u001b[0;34m(step)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimulationStep\u001b[39m(step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"simulationStep(float) -> None\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    Make a simulation step and simulate up to the given second in sim time.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    If the given value is 0 or absent, exactly one step is performed.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    Values smaller than or equal to the current sim time result in no action.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulationStep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/RL_traffic/lib/python3.10/site-packages/traci/connection.py:370\u001b[0m, in \u001b[0;36mConnection.simulationStep\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(step) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[1;32m    369\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI change now handles step as floating point seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 370\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendCmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCMD_SIMSTEP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subscriptionResults \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_subscriptionMapping\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    372\u001b[0m     subscriptionResults\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/RL_traffic/lib/python3.10/site-packages/traci/connection.py:232\u001b[0m, in \u001b[0;36mConnection._sendCmd\u001b[0;34m(self, cmdID, varID, objID, format, *values)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(objID)) \u001b[38;5;241m+\u001b[39m objID\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m packed\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendExact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/RL_traffic/lib/python3.10/site-packages/traci/connection.py:131\u001b[0m, in \u001b[0;36mConnection._sendExact\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msending\u001b[39m\u001b[38;5;124m\"\u001b[39m, Storage(length \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_string)\u001b[38;5;241m.\u001b[39mgetDebugString())\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39msend(length \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_string)\n\u001b[0;32m--> 131\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recvExact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _DEBUG:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceiving\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mgetDebugString())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/RL_traffic/lib/python3.10/site-packages/traci/connection.py:109\u001b[0m, in \u001b[0;36mConnection._recvExact\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m()\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m--> 109\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t:\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "type_model = \"2DQN\"\n",
    "inputs_per_agents, outputs_per_agents = preprocess()\n",
    "train_models(inputs_per_agents, outputs_per_agents,type_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_traffic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
